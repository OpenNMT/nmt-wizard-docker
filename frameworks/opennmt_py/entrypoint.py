import os
import copy
import six
import json
import requests

from nmtwizard.framework import Framework
from nmtwizard.logger import get_logger
from nmtwizard import utils, serving

logger = get_logger(__name__)

_MODEL_NAME = "model.pt"
_RELEASED_MODEL_NAME = "model_released.pt"


class OpenNMTPYFramework(Framework):
    def __init__(self):
        super(OpenNMTPYFramework, self).__init__()
        self._onmt_py_dir = os.getenv('OPENNMT_PY_DIR', '/root/OpenNMT-py')

    def train(self,
              config,
              src_file,
              tgt_file,
              src_vocab_info,
              tgt_vocab_info,
              align_file=None,
              model_path=None,
              gpuid=0):
        # Preprocess training files.
        options_preprocess = copy.deepcopy(config['options']['config']['preprocess'])
        options_preprocess['src_vocab'] = self._convert_vocab(
            config['tokenization']['source']['vocabulary'])
        options_preprocess['tgt_vocab'] = self._convert_vocab(
            config['tokenization']['target']['vocabulary'])
        bin_file = os.path.join(self._data_dir, "bin")
        cmd = ["python", "preprocess.py",
               "-train_src", src_file,
               "-train_tgt", tgt_file,
               "-save_data", bin_file]
        cmd += _build_cmd(options_preprocess)
        self._run_cmd(cmd)

        # Train.
        options_train = copy.deepcopy(config['options']['config']['train'])
        if "train_steps" not in options_train:
            options_train["single_pass"] = True
            options_train["train_steps"] = 0
        options_train["save_checkpoint_steps"] = 0
        options_train["data"] = bin_file
        options_train["save_model"] = self._output_dir + "/model"
        if isinstance(gpuid, list):
            options_train["world_size"] = len(gpuid)
            options_train["gpu_ranks"] = " ".join(str(i - 1) for i in gpuid)
        elif gpuid > 0:
            options_train["gpu_ranks"] = gpuid - 1
        if model_path is not None:
            options_train["train_from"] = os.path.join(model_path, _MODEL_NAME)
        self._run_cmd(["python", "train.py"] + _build_cmd(options_train))

        # Select model.
        models = os.listdir(self._output_dir)
        if not models:
            raise RuntimeError('no model generated by the training')
        if len(models) > 1:
            raise RuntimeError('more than one model generated by the training')
        model_file = os.path.join(self._output_dir, models[0])
        return {_MODEL_NAME: model_file}

    def trans(self, config, model_path, input, output, gpuid=0):
        options_trans = _trans_options(config, gpuid)
        options_trans["model"] = os.path.join(model_path, _MODEL_NAME)
        options_trans["src"] = input
        options_trans["output"] = output
        self._run_cmd(["python", " translate.py"] + _build_cmd(options_trans))

    def serve(self, config, model_path, gpuid=0):
        server_config_path = os.path.join(self._output_dir, "conf.json")
        with open(server_config_path, "w") as server_config_file:
            json.dump({
                "models_root": model_path,
                "models": [
                    {
                        "id": 0,
                        "model": _RELEASED_MODEL_NAME,
                    "opt": _trans_options(config, gpuid)
                    }
                ]
            }, server_config_file)
        port = serving.pick_free_port()
        process = self._run_cmd([
            "python", "server.py",
            "--ip", "127.0.0.1",
            "--port", str(port),
            "--url_root", "/translator-backend",
            "--config", server_config_path
        ],  background=True)
        return process, {"port": port}

    def release(self, config, model_path, gpuid=0):
        model = os.path.join(model_path, _MODEL_NAME)
        released_model = os.path.join(self._output_dir, _RELEASED_MODEL_NAME)
        self._run_cmd(["python", "tools/release_model.py", "-m", model, "-o", released_model])
        return {_RELEASED_MODEL_NAME: released_model}

    def forward_request(self, batch_inputs, info, timeout=None):
        data = [{"src": " ".join(tokens), "id": 0} for tokens in batch_inputs]
        try:
            result = requests.post(
                "http://127.0.0.1:%d/translator-backend/translate" % info["port"],
                json=data,
                timeout=timeout)
            return [
                [serving.TranslationOutput(r["tgt"].split(), score=r["pred_score"])]
                for r in result.json()[0]]
        except requests.exceptions.Timeout as e:
            logger.error('%s', e)
            return None

    def _map_vocab_entry(self, index, token, vocab):
        if index == 0:
            vocab.write(b"<unk>\n")
            vocab.write(b"<blank>\n")
            vocab.write(b"<s>\n")
            vocab.write(b"</s>\n")
        vocab.write(b"%s\n" % token)

    def _run_cmd(self, cmd, background=False):
        return utils.run_cmd(cmd, cwd=self._onmt_py_dir, background=background)


def _trans_options(config, gpuid):
    opt = copy.deepcopy(config['options']['config']['trans'])
    if gpuid > 0:
        opt["gpu"] = gpuid - 1
    return opt

def _build_cmd(options):
    opts = []
    for k, v in six.iteritems(options):
        if isinstance(v, bool):
            if v:
                opts.append('-%s' % k)
        else:
            opts.append('-%s' % k)
            opts.append(str(v))
    return opts


if __name__ == '__main__':
    OpenNMTPYFramework().run()
